{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b830b1fb-4324-426c-8e44-d48ab3b6f341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "componentes de sklearn\n",
      "estimadores \n",
      "transformadores\n",
      "pedictores\n"
     ]
    }
   ],
   "source": [
    "print(\"componentes de sklearn\")\n",
    "print(\"estimadores \")\n",
    "print(\"transformadores\")\n",
    "print(\"pedictores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "263c0fcc-e788-4586-9e5d-bf3f45bfa898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import uuid\n",
    "import hashlib\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "#permite que le coloquemos ; en vez de show()\n",
    "import seaborn as sns \n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression , LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0512e28e-9b94-467b-b9f8-f117b4e93d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b55d61-de7a-4709-897f-634130dbfd49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c02e0fc-06b1-48b8-b0f3-7e0615916e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "las predicciones son: [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 2]\n",
      "la precision del modelo es: 0.97\n"
     ]
    }
   ],
   "source": [
    "#print(\"cargamos el dataset\")\n",
    "data = load_iris()\n",
    "X=data.data\n",
    "y=data.target\n",
    "#print(\"dividimos en entrenamiento y prueba\")\n",
    "X_entrena, X_prueba,y_entrena, y_prueba = train_test_split(X,y,\n",
    "                                                           test_size=0.25,\n",
    "                                                           random_state=0)\n",
    "#print(\"creamos la instancia escalador\")\n",
    "scaler = StandardScaler()\n",
    "#print(\"estimador, aprendemos los parametros de fit\")\n",
    "scaler.fit(X_entrena)\n",
    "#print(\"transformador,aplicamos la transformacion a los datos\")\n",
    "X_entrena_escalado=scaler.transform(X_entrena)\n",
    "X_prueba_escalado =scaler.transform(X_prueba)\n",
    "#print(\"creamos la instancia modelo\")\n",
    "modelo = LogisticRegression()\n",
    "#print(\"estimador, entrenamos el modelo\")\n",
    "modelo.fit(X_entrena_escalado, y_entrena)\n",
    "#print(\"predictor, hacemos predicciones y evaluamos el modelo\")\n",
    "y_pred=modelo.predict(X_prueba_escalado)\n",
    "puntaje = modelo.score(X_prueba_escalado, y_prueba)\n",
    "print(f\"las predicciones son: {y_pred}\")\n",
    "print(f\"la precision del modelo es: {puntaje:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fbb88c2-1656-4740-91e8-6247ace495c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.        , 1.        ],\n",
       "       [1.        , 0.5       , 0.33333333],\n",
       "       [0.        , 1.        , 0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=np.array([[1,-1,2],[2,0,0],[0,1,-1]])\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "d_escalada = scaler.fit_transform(d)\n",
    "d_escalada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a185d067-5c21-4612-be23-23e71ba54ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]]\n",
      "[[0.22222222 0.625      0.06779661 0.04166667]\n",
      " [0.16666667 0.41666667 0.06779661 0.04166667]\n",
      " [0.11111111 0.5        0.05084746 0.04166667]]\n"
     ]
    }
   ],
   "source": [
    "i = load_iris()\n",
    "X=i.data\n",
    "scaler =MinMaxScaler(feature_range=(0,1))\n",
    "X_escalado = scaler.fit_transform(X)\n",
    "print(X[:3]) #datos originales\n",
    "print(X_escalado[:3]) #transformada entre 0 y 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50391dbb-3de1-4a30-bdd1-7898c230caf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandarScaler\n"
     ]
    }
   ],
   "source": [
    "print(\"StandarScaler\")\n",
    "#para que tenga un array de media de cero y una desviacion estandar \n",
    "# de 1 para algortimos que asumen que tiene una distribucion normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a010d17c-9ee6-4ebb-87c3-25b656729c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler2 = StandardScaler()\n",
    "d_escalada2=scaler2.fit_transform(d)\n",
    "d_escalada2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfc91108-ea8f-4fbb-bbbc-3e53b39415ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(d_escalada2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae0136b9-e6a5-405c-9bd1-3741bb5b3b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One hot Encoder\n"
     ]
    }
   ],
   "source": [
    "#solo se usa para var categoricas en numeros binarios \n",
    "print(\"One hot Encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99175b7c-9d3f-4ca8-9580-c98e85749617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorias = np.array([[\"rojo\"],[\"verde\"],[\"azul\"],[\"verde\"],[\"verde\"],[\"azul\"]])\n",
    "encoder = OneHotEncoder(sparse_output=False)#evitamos una matrix dispersa \n",
    "data_codificada = encoder.fit_transform(categorias)\n",
    "data_codificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "978c72e9-0926-4c69-95e7-082d7e6c66dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamaño del conjunto total 150\n",
      "tamaño del conjunto de train 120\n",
      "tamaño del conjunto de pruebas 30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, SelectFromModel, chi2\n",
    "a = load_iris()\n",
    "X=data.data\n",
    "y=data.target\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y,test_size=0.2, random_state=42)\n",
    "print(\"tamaño del conjunto total\", len(X))\n",
    "print(\"tamaño del conjunto de train\", len(X_train))\n",
    "print(\"tamaño del conjunto de pruebas\", len(X_test))\n",
    "selector =SelectKBest(chi2, k=2)#quiero saber las 2 caracteristicas mas importantes\n",
    "X_nuevo=selector.fit_transform(X_train, y_train)\n",
    "m = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "selector2 = SelectFromModel(m)\n",
    "X_importante =selector2.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8742347-7ee7-4c92-90ac-378500c78d69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
